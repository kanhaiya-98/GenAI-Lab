# ğŸ¤– Conversational RAG Q\&A with PDF Uploads & Chat History

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue?logo=python" />
  <img src="https://img.shields.io/badge/Streamlit-App-red?logo=streamlit" />
  <img src="https://img.shields.io/badge/LangChain-Orchestration-orange?logo=chainlink" />
  <img src="https://img.shields.io/badge/Groq-LLM-black?logo=groq" />
  <img src="https://img.shields.io/badge/HuggingFace-Embeddings-yellow?logo=huggingface" />
  <img src="https://img.shields.io/badge/Chroma-VectorDB-green?logo=redis" />
</p>  

<p align="center">
  <img src="https://img.shields.io/github/stars/kanhaiya-98/GenAI-Lab?style=social" />
  <img src="https://img.shields.io/github/forks/kanhaiya-98/GenAI-Lab?style=social" />
</p>  

---

## ğŸš€ What is this?

An **AI-powered Q\&A assistant** that lets you:

* Upload **PDFs** ğŸ“‘
* Ask **conversational questions** ğŸ’¬
* Get **context-aware answers** âš¡
* Keep **chat history** persistent ğŸ”„

Built with **Streamlit + LangChain + Groq + Hugging Face + Chroma DB**.

---

## âœ¨ Features

âœ… **PDF Upload** â€“ Single or multiple files.
âœ… **Conversational Chat** â€“ Natural dialogue with your docs.
âœ… **Persistent Memory** â€“ Session-based chat history.
âœ… **RAG Pipeline** â€“ Retrieval before generation for accuracy.
âœ… **Groq LLM** â€“ Lightning-fast inference.
âœ… **Secure Keys** â€“ `.env` for Hugging Face & Groq.

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,streamlit,azure,git,github" />
</p>  

---

## âš™ï¸ How It Works

```mermaid
flowchart TD
    A[ğŸ“‚ PDF Upload] --> B[ğŸ” Chunking & Embedding]
    B --> C[ğŸ—„ï¸ Vector Store - Chroma]
    C --> D[ğŸ“œ Query Reformulation - History Aware]
    D --> E[ğŸ” Similarity Search]
    E --> F[âš¡ Groq LLM (Gemma-9b-it)]
    F --> G[ğŸ¤– Answer Generated]
```

---

## ğŸ› ï¸ Tech Stack

* **UI** â†’ Streamlit
* **Orchestration** â†’ LangChain
* **LLM** â†’ Groq (Gemma2-9b-It)
* **Embeddings** â†’ Hugging Face (all-MiniLM-L6-v2)
* **Vector Store** â†’ Chroma DB
* **Loader** â†’ PyPDFLoader
* **Env Mgmt** â†’ python-dotenv

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,pytorch,docker" />  
</p>  

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

* Python **3.8+**
* `pip`

### âš¡ Setup

```bash
# 1. Clone
git clone https://github.com/kanhaiya-98/GenAI-Lab.git
cd GenAI-Lab

# 2. Virtual Environment
python -m venv venv
# Windows
.\venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# 3. Install Dependencies
pip install -r RAG-Q&A-WITH-PDF-&-CHAT-HISTORY/requirements.txt

# 4. Configure .env
HF_TOKEN="your_hugging_face_api_token"

# 5. Run
streamlit run RAG-Q&A-WITH-PDF-&-CHAT-HISTORY/app.py
```

---

## ğŸ“– Usage

1. ğŸ”‘ Enter **Groq API key** (get from [Groq Console](https://console.groq.com/))
2. ğŸ†” Set a **Session ID** (optional, keeps chats separate)
3. ğŸ“‚ Upload PDFs
4. ğŸ’¬ Ask questions â†’ Get AI answers with history

---

## ğŸ“¸ Screenshots

